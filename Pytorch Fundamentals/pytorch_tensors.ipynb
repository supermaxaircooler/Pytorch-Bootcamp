{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "VECTOR = torch.tensor([1,2,4])\n",
    "print(VECTOR.ndim)\n",
    "print(VECTOR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.tensor always copies the input `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[2,5,5]])\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2550, 0.0744, 0.8124, 0.1587],\n",
       "        [0.2818, 0.5873, 0.6166, 0.0604],\n",
       "        [0.1798, 0.6956, 0.3319, 0.2347]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensors = torch.rand(3,4)\n",
    "print(random_tensors.ndim)\n",
    "random_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available. Training will run on CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(size = (3,5) , dtype = torch.int64)\n",
    "zeros = torch.zeros(size = (4,5) , dtype = torch.float64)\n",
    "\n",
    "print(zeros.dtype)\n",
    "print(ones.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating range tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensors_range = torch.arange(start = 1 , end = 5, step = 2)\n",
    "\n",
    "tensors_like_range = torch.zeros(size = tensors_range.shape , dtype = tensors_range.dtype , layout=  tensors_range.layout)\n",
    "\n",
    "#alternate function \n",
    "zeros_like_range = torch.zeros_like(tensors_range)\n",
    "tensors_like_range.shape\n",
    "zeros_like_range.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "torch.tensor() always copies data. If you have a Tensor data and just want to change its requires_grad flag, use requires_grad_() or detach() to avoid a copy. If you have a numpy array and want to avoid a copy, use torch.as_tensor()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you try to compute 2 tensors which are on different device, there will be an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 5., 9.], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_64_tensor = torch.tensor([3 , 5, 9] , dtype = torch.double , \n",
    "                               device = None , \n",
    "                               requires_grad=  True)\n",
    "float_64_tensor.dtype\n",
    "float_64_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor = float_64_tensor.type(torch.half)\n",
    "float16_tensor.dtype\n",
    "# float_64_tensor.shape\n",
    "\n",
    "# default is torch.float32 or torch.float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensor.size() and tensor.shape \n",
    "tensor.size() is a function or method \n",
    "tensor.shape is an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.mm - performs a matrix multiplication without broadcasting - (2D tensor) by (2D tensor) \\\n",
    "torch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number) \\\n",
    "torch.matmul - matrix product with broadcasting - (Tensor) by (Tensor) with different behaviors depending on the tensor shapes (dot product, matrix product, batched matrix products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float16_tensor = torch.ShortTensor([1,2,3])\n",
    "int16_tensor = torch.IntTensor([1,2,3])\n",
    "int16_tensor\n",
    "float16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data type                                           CPU tensor                                                          GPU tensor \\\n",
    "\n",
    "32-bit floating point                           torch.FloatTensor                                                     torch.cuda.FloatTensor\n",
    "\n",
    "64-bit floating point                           torch.DoubleTensor                                                    torch.cuda.DoubleTensor\n",
    "\n",
    "16-bit floating point                           torch.HalfTensor                                                       torch.cuda.HalfTensor\n",
    "\n",
    "16-bit floating point                           torch.BFloat16Tensor                                                    torch.cuda.BFloat16Tensor\n",
    "\n",
    "8-bit integer (unsigned)                        torch.ByteTensor                                                         torch.cuda.ByteTensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.max(input, dim , keepdims , * , out = None) -> Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1,101,10)\n",
    "\n",
    "torch.min(x)\n",
    "x.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.mean(input , dim, keepdims, *,  dtype = None , out = None) ->Tensor `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46., dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.mean(x.type(torch.double))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.mean(x) \\\n",
    "throws error\n",
    "\n",
    "common programming courtesy :\\\n",
    "dont expect the output data type to be different from the input's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(46., dtype=torch.float16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x , dtype = torch.half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(460)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.sum(input, *, dtype=None) → Tensor`\n",
    "\n",
    "`input (Tensor) `– the input tensor. \n",
    "\n",
    "`dim` (int or tuple of ints, optional) – the dimension or \n",
    "dimensions to reduce. If None, all dimensions are reduced.  \n",
    "\n",
    "`keepdim (bool)` – whether the output tensor has dim retained or  not. \n",
    "\n",
    "`dtype (torch.dtype, optional) `– the desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed. This is useful for preventing data type overflows. Default: None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.argmax(input) → LongTensor `\n",
    "Returns the indices of the maximum value of all elements in the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7319,  0.0813,  0.5135,  1.3430],\n",
       "        [-0.6131, -0.3220, -0.1060,  0.0666],\n",
       "        [ 1.1868,  1.5562,  1.6909, -0.6307],\n",
       "        [ 0.0967, -0.0808, -0.9787,  1.2553]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `input (Tensor) – the input tensor. `\n",
    "\n",
    "`dim (int) `– the dimension to reduce. If None, the argmax of the flattened input is returned.\n",
    "\n",
    "`keepdim (bool)` – whether the output tensor has dim retained or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 2, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.argmax(a, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2, 2, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(a, dim = 0 , keepdims = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.reshape(input, shape) → Tensor`\n",
    "Returns a tensor with the same data and number of elements as input, but with the specified shape. When possible, the returned tensor will be a view of input. Otherwise, it will be a copy. Contiguous inputs and inputs with compatible strides can be reshaped without copying, but you should not depend on the copying vs. viewing behavior.\n",
    "\n",
    "See `torch.Tensor.view()` on when it is possible to return a view. which will throw an error if the operation cannot be done without copying the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.stack(tensors, dim=0, *, out=None) → Tensor`\n",
    "Concatenates a sequence of tensors along a new dimension.\n",
    "\n",
    "All tensors need to be of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 4]), torch.Size([3, 2, 4]), torch.Size([3, 4, 2]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,4)\n",
    "y = torch.randn(2,4)\n",
    "\n",
    "\n",
    "# x and y stack not possible\n",
    "\n",
    "xx = torch.stack((x, x), dim = 0)\n",
    "x2 = torch.stack((x,x) , dim = 1)\n",
    "x3 = torch.stack((x,x) , dim = 2)\n",
    "xx.shape , x2.shape , x3.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 4]), torch.Size([3, 8]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "xcat = torch.cat((x,x), dim = 0)\n",
    "ycat = torch.cat((x,x), dim = 1)\n",
    "xcat.shape , ycat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.squeeze(input, dim)`\n",
    "\n",
    "Returns a tensor with all specified dimensions of input of size 1 removed.\n",
    "\n",
    "For example, if input is of shape: \n",
    "(\n",
    "A\n",
    "×\n",
    "1\n",
    "×\n",
    "B\n",
    "×\n",
    "C\n",
    "×\n",
    "1\n",
    "×\n",
    "D\n",
    ")\n",
    "(A×1×B×C×1×D) then the input.squeeze() will be of shape: \n",
    "(\n",
    "A\n",
    "×\n",
    "B\n",
    "×\n",
    "C\n",
    "×\n",
    "D\n",
    ")\n",
    "(A×B×C×D).\n",
    "\n",
    "When dim is given, a squeeze operation is done only in the given dimension(s). If input is of shape: \n",
    "(\n",
    "A\n",
    "×\n",
    "1\n",
    "×\n",
    "B\n",
    ")\n",
    "(A×1×B), squeeze(input, 0) leaves the tensor unchanged, but squeeze(input, 1) will squeeze the tensor to the shape \n",
    "(\n",
    "A\n",
    "×\n",
    "B\n",
    ")\n",
    "(A×B).\n",
    "\n",
    "dim also accepts tuple of dimensions\n",
    "\n",
    "If the tensor has a batch dimension of size 1, then squeeze(input) will also remove the batch dimension, which can lead to unexpected errors. Consider specifying only the dims you wish to be squeezed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.unsqueeze(input, dim)`\n",
    "Returns a new tensor with a dimension of size one inserted at the specified position.\n",
    "\n",
    "The returned tensor shares the same underlying data with this tensor.\n",
    "\n",
    "A dim value within the range [-input.dim() - 1, input.dim() + 1) can be used. Negative dim will correspond to unsqueeze() applied at dim = dim + input.dim() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` torch.permute(torch.permute(input, dims) → Tensor `\n",
    "Returns a view of the original tensor input with its dimensions permuted.\n",
    "\n",
    "Parameters\n",
    "input (Tensor) – the input tensor.\n",
    "\n",
    "dims (tuple of int) – The desired ordering of dimensions)\n",
    "\n",
    "\n",
    "### same as nuumpy.transpose(input, axes = ())  😔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.from_numpy(ndarray) → Tensor`\n",
    "Creates a Tensor from a numpy.ndarray.\n",
    "\n",
    "The returned tensor and ndarray share the same memory. Modifications to the tensor will be reflected in the ndarray and vice versa. The returned tensor is not resizable.\n",
    "\n",
    "tensor default dtype is Tensor.float32 and numpy default dtype is np.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same tensors\n"
     ]
    }
   ],
   "source": [
    "random_seed = 4\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "tensora = torch.randn(3,3)\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "tensorc = torch.randn(3,3)\n",
    "\n",
    "\n",
    "if((tensora == tensorc)).all():\n",
    "    print(\"same tensors\")\n",
    "\n",
    "else :\n",
    "    print(\"different tensors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Strided Tensor`\n",
    "1. Memory Layout: A strided tensor is the default dense tensor in PyTorch. The data is stored in a contiguous block of memory, but the way elements are accessed is controlled by the stride of the tensor.\n",
    "2. Strides: Strides are a set of integers that indicate the number of memory locations to skip to move to the next element along each dimension. For example, if a 2D tensor has a shape of (3, 4) and strides (4, 1), it means that moving one step along the first dimension (rows) involves skipping 4 memory locations, while moving along the second dimension (columns) involves skipping 1 location.\n",
    "3. Efficiency: Strided tensors are efficient for most operations since they provide direct access to the elements in memory.\n",
    "Reshape and View: Operations like torch.reshape and torch.view work well with strided tensors, especially if the tensor is contiguous (i.e., the strides are such that the tensor elements are stored sequentially in memory).\n",
    "### `Sparse Tensor`\n",
    "1 .Memory Layout: A sparse tensor is used to efficiently store and operate on tensors that have a large number of zero elements. Instead of storing all elements, only the non-zero elements and their locations are stored. \\\n",
    "2. Storage: Sparse tensors are usually represented using two main components: \\\n",
    "        -Indices: A tensor that stores the indices of the non-zero elements. \\\n",
    "        -Values: A tensor that stores the values of the non-zero elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.view() `\n",
    "In PyTorch and NumPy, a \"view\" of a tensor or array is a way of accessing the same underlying data in memory with a different shape or stride configuration. Here's how it works:\n",
    "\n",
    "1. Understanding Views\n",
    "A view is a new tensor (or array) that shares the same data as the original tensor but might have a different shape, stride, or order of elements.\n",
    "\n",
    "2. Memory Layout and Strides\n",
    "Memory Layout: Tensors and arrays are stored in contiguous blocks of memory. For example, in a 2D tensor, elements are laid out row by row in memory (this is called \"row-major order\" or \"C-style\" ordering).\n",
    "\n",
    "Strides: Strides define how many steps in memory you need to take to move from one element to the next along each dimension. For example, in a 2D tensor with shape (3, 4), the stride could be (4, 1), meaning to move along the first dimension (rows), you move 4 steps in memory, and to move along the second dimension (columns), you move 1 step in memory.\n",
    "\n",
    "3. Creating Views\n",
    "When you create a view, you're essentially telling the system to interpret the existing data differently without copying it. For example, you might reshape a tensor from (6,) to (2, 3). The new shape and strides allow you to index the same data differently.\n",
    "\n",
    "\n",
    "4. Memory Efficiency\n",
    "Since views do not involve copying data, they are memory-efficient. Instead of allocating new memory, the view tensor just reinterprets the memory layout of the original tensor.\n",
    "5. `Contiguity`\n",
    "` A tensor is \"contiguous\" if its elements are stored in a contiguous block of memory. Operations like reshaping often result in contiguous tensors, but some operations may result in non-contiguous tensors. If a tensor is not contiguous, some operations may require making it contiguous first, which involves copying the data.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`contiguous()` returns itself if input tensor is already contiguous, otherwise it returns a new contiguous tensor by copying data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor is contiguous : True\n",
      "transpose tensor is contiguous : False\n",
      "tensor([[ 1.3055, -2.1691, -0.2993],\n",
      "        [ 0.1070,  0.4707,  0.9054],\n",
      "        [-0.1010, -0.4063, -0.9879],\n",
      "        [-0.3921,  2.2503, -0.3762]])\n",
      "reshaped tensor is contiguous : False\n",
      "the contiguos reshaped tensor is continguos : True\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn(3,4)\n",
    "\n",
    "print(f\"tensor is contiguous : {tensor.is_contiguous()}\")\n",
    "\n",
    "tensort = tensor.T\n",
    "\n",
    "print(f\"transpose tensor is contiguous : {tensort.is_contiguous()}\")\n",
    "\n",
    "print(tensort)\n",
    "\n",
    "reshaped_tensor  = torch.reshape(tensort , (4,3))\n",
    "\n",
    "print(f\"reshaped tensor is contiguous : {reshaped_tensor.is_contiguous()}\")\n",
    "\n",
    "contiguous_reshaped_tensor = torch.Tensor.contiguous(reshaped_tensor)\n",
    "\n",
    "# contiguous_reshaped_tensor = reshaped_tensor.contiguous()        it is an attribute of the object\n",
    "\n",
    "print(f\"the contiguos reshaped tensor is continguos : {contiguous_reshaped_tensor.is_contiguous()}\")\n",
    "\n",
    "print(reshaped_tensor.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.transpose(input, dim0, dim1) → Tensor `\n",
    "Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.\n",
    "\n",
    "If input is a strided tensor then the resulting out tensor shares its underlying storage with the input tensor, so changing the content of one would change the content of the other.\n",
    "\n",
    "If input is a sparse tensor then the resulting out tensor does not share the underlying storage with the input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
